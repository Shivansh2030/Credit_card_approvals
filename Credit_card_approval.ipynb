{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bab27250-fec3-4c72-9a8d-9a6026fa95d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.250</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00202</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.040</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.500</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.750</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.710</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b</td>\n",
       "      <td>32.08</td>\n",
       "      <td>4.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>v</td>\n",
       "      <td>2.500</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00360</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b</td>\n",
       "      <td>33.17</td>\n",
       "      <td>1.040</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>r</td>\n",
       "      <td>h</td>\n",
       "      <td>6.500</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00164</td>\n",
       "      <td>31285</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a</td>\n",
       "      <td>22.92</td>\n",
       "      <td>11.585</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>cc</td>\n",
       "      <td>v</td>\n",
       "      <td>0.040</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00080</td>\n",
       "      <td>1349</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b</td>\n",
       "      <td>54.42</td>\n",
       "      <td>0.500</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>h</td>\n",
       "      <td>3.960</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00180</td>\n",
       "      <td>314</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b</td>\n",
       "      <td>42.50</td>\n",
       "      <td>4.915</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.165</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00052</td>\n",
       "      <td>1442</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0      1       2  3  4   5  6      7  8  9   10 11 12     13     14 15\n",
       "0  b  30.83   0.000  u  g   w  v  1.250  t  t   1  f  g  00202      0  +\n",
       "1  a  58.67   4.460  u  g   q  h  3.040  t  t   6  f  g  00043    560  +\n",
       "2  a  24.50   0.500  u  g   q  h  1.500  t  f   0  f  g  00280    824  +\n",
       "3  b  27.83   1.540  u  g   w  v  3.750  t  t   5  t  g  00100      3  +\n",
       "4  b  20.17   5.625  u  g   w  v  1.710  t  f   0  f  s  00120      0  +\n",
       "5  b  32.08   4.000  u  g   m  v  2.500  t  f   0  t  g  00360      0  +\n",
       "6  b  33.17   1.040  u  g   r  h  6.500  t  f   0  t  g  00164  31285  +\n",
       "7  a  22.92  11.585  u  g  cc  v  0.040  t  f   0  f  g  00080   1349  +\n",
       "8  b  54.42   0.500  y  p   k  h  3.960  t  f   0  f  g  00180    314  +\n",
       "9  b  42.50   4.915  y  p   w  v  3.165  t  f   0  t  g  00052   1442  +"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "cc_apps = pd.read_csv(r\"C:\\Users\\shivr\\PycharmProjects\\Credit_card_approval\\crx.data\", header=None)\n",
    "\n",
    "cc_apps.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "880bd0e6-eed5-40fe-817d-2cf61f5ba26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               2           7          10             14\n",
      "count  690.000000  690.000000  690.00000     690.000000\n",
      "mean     4.758725    2.223406    2.40000    1017.385507\n",
      "std      4.978163    3.346513    4.86294    5210.102598\n",
      "min      0.000000    0.000000    0.00000       0.000000\n",
      "25%      1.000000    0.165000    0.00000       0.000000\n",
      "50%      2.750000    1.000000    0.00000       5.000000\n",
      "75%      7.207500    2.625000    3.00000     395.500000\n",
      "max     28.000000   28.500000   67.00000  100000.000000\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       690 non-null    object \n",
      " 1   1       690 non-null    object \n",
      " 2   2       690 non-null    float64\n",
      " 3   3       690 non-null    object \n",
      " 4   4       690 non-null    object \n",
      " 5   5       690 non-null    object \n",
      " 6   6       690 non-null    object \n",
      " 7   7       690 non-null    float64\n",
      " 8   8       690 non-null    object \n",
      " 9   9       690 non-null    object \n",
      " 10  10      690 non-null    int64  \n",
      " 11  11      690 non-null    object \n",
      " 12  12      690 non-null    object \n",
      " 13  13      690 non-null    object \n",
      " 14  14      690 non-null    int64  \n",
      " 15  15      690 non-null    object \n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 86.4+ KB\n",
      "None\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>b</td>\n",
       "      <td>19.50</td>\n",
       "      <td>0.290</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>0.290</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>364</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.000</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>3.000</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00176</td>\n",
       "      <td>537</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>b</td>\n",
       "      <td>17.08</td>\n",
       "      <td>3.290</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>i</td>\n",
       "      <td>v</td>\n",
       "      <td>0.335</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00140</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>b</td>\n",
       "      <td>36.42</td>\n",
       "      <td>0.750</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>d</td>\n",
       "      <td>v</td>\n",
       "      <td>0.585</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00240</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>b</td>\n",
       "      <td>40.58</td>\n",
       "      <td>3.290</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>v</td>\n",
       "      <td>3.500</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>s</td>\n",
       "      <td>00400</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>b</td>\n",
       "      <td>21.08</td>\n",
       "      <td>10.085</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>h</td>\n",
       "      <td>1.250</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00260</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>a</td>\n",
       "      <td>22.67</td>\n",
       "      <td>0.750</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>v</td>\n",
       "      <td>2.000</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00200</td>\n",
       "      <td>394</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>a</td>\n",
       "      <td>25.25</td>\n",
       "      <td>13.500</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>ff</td>\n",
       "      <td>ff</td>\n",
       "      <td>2.000</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00200</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>b</td>\n",
       "      <td>17.92</td>\n",
       "      <td>0.205</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>aa</td>\n",
       "      <td>v</td>\n",
       "      <td>0.040</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>750</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>b</td>\n",
       "      <td>35.00</td>\n",
       "      <td>3.375</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>h</td>\n",
       "      <td>8.290</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00000</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0      1       2  3  4   5   6      7  8  9   10 11 12     13   14 15\n",
       "680  b  19.50   0.290  u  g   k   v  0.290  f  f   0  f  g  00280  364  -\n",
       "681  b  27.83   1.000  y  p   d   h  3.000  f  f   0  f  g  00176  537  -\n",
       "682  b  17.08   3.290  u  g   i   v  0.335  f  f   0  t  g  00140    2  -\n",
       "683  b  36.42   0.750  y  p   d   v  0.585  f  f   0  f  g  00240    3  -\n",
       "684  b  40.58   3.290  u  g   m   v  3.500  f  f   0  t  s  00400    0  -\n",
       "685  b  21.08  10.085  y  p   e   h  1.250  f  f   0  f  g  00260    0  -\n",
       "686  a  22.67   0.750  u  g   c   v  2.000  f  t   2  t  g  00200  394  -\n",
       "687  a  25.25  13.500  y  p  ff  ff  2.000  f  t   1  t  g  00200    1  -\n",
       "688  b  17.92   0.205  u  g  aa   v  0.040  f  f   0  f  g  00280  750  -\n",
       "689  b  35.00   3.375  u  g   c   h  8.290  f  f   0  t  g  00000    0  -"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspecting the dataframe\n",
    "cc_apps_description = cc_apps.describe()\n",
    "print(cc_apps_description)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "cc_apps_info = cc_apps.info()\n",
    "print(cc_apps_info)\n",
    "print('\\n')\n",
    "\n",
    "cc_apps.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8488778-b515-4cd7-b0ba-cb93868b397d",
   "metadata": {},
   "source": [
    "Splitting the dataset into train and test sets :\r",
    " we will split our data into train set and test set to prepare our data for two different phases of machine learning modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0304108-736c-4b38-ab8d-ddf84d3e2e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Drop the features 11 and 13\n",
    "cc_apps = cc_apps.drop([11, 13], axis=1)\n",
    "\n",
    "# Split into train and test sets\n",
    "cc_apps_train, cc_apps_test = train_test_split(cc_apps, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3c8d0cf-8878-4116-98e7-a23863c92365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the '?'s with NaN in the train and test sets\n",
    "cc_apps_train = cc_apps_train.replace('?', np.NaN)\n",
    "cc_apps_test = cc_apps_test.replace('?', np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f1b456c-7afd-4782-aa32-044ae135a5cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert ['baabbbbabbbbababbababbaaaaabbbbbbaabbabbbbbbbbabbbabbbbbbbbbbbaabbabbbbbabbbbabbbababbbbbabbbbbabbaabbbbbbbabababababbbabbaaabbbbabbabbbbbaaaabbbbbaaaaabbbaaabbbbbbaababbabbabbbaabbaaaabbbaabbbbbbbbbbaababaabbbbbbbbbbbbaabaaabbabbbabbaabbbbbbbabbba?bbbabbbbbaabaaabbbabbbbbbbbaabbbbbabbabbababbaabbbbabbaabbbbaabaabbbbbbbaabbab?bbbababbbaababbbbb?bbbabbbbababaabbbbbababbbab?abbbbbaaabbbbbbbbbbbababbbbaabaaabbbbabbabbbabbbbbbabbbbbbbbbbaabbbbbaababbbbb?bbbbbbabbaaababbabbbbbbbb?ababbbbbb?abbaababbbbbababaaabbaabbbabab?abaabbaabaabbbaabbbbbbbbbbbbbbbbbabbabaabbbbabababbbaabbbbbbbbbabbbbbbbbbbbaa?ba?bbbabbbbbbbbabbbbbbbabbbbbbaaaababbbbbb?babbabbabaabaabaaabbabbbaabbbba?aaabaabbbbbbaabb'\n '30.8358.6724.5027.8320.1732.0833.1722.9254.4242.5022.0829.9238.2548.0845.8336.6728.2523.2521.8319.1725.0023.2547.7527.4241.1715.8347.0056.5857.4242.0829.2542.0049.5036.7522.5827.8327.2523.0027.7554.5834.1728.9229.6739.5856.4254.3341.0031.9241.5023.9225.7526.0037.4234.9234.2523.3323.1744.3335.1743.2556.7531.6723.4220.4226.6734.1736.0025.5019.4235.1732.3334.8338.5844.2544.8320.6734.0819.1721.6721.5049.5827.6739.83?27.2537.17?25.6734.0049.0062.5031.42?52.3328.7528.5823.00?22.5028.5037.5035.2518.6725.0027.8354.8328.7525.0040.9219.7529.1724.5024.5833.7520.6725.4237.7552.5057.8320.7539.9225.6724.7544.1723.5034.9247.6722.7534.4228.4267.7520.4247.4236.2532.6748.5839.9233.5818.8326.9231.2556.5043.0022.3327.2532.8323.2540.3330.5052.8346.6758.3337.3323.0832.7521.6728.5068.6728.0034.0827.6744.0025.0832.0060.5840.8319.3332.3336.6737.5025.0841.3356.0049.8322.6727.0025.0026.0818.4220.1747.6721.2520.6757.0822.4248.7540.0040.5828.6733.0821.3342.0041.7522.6734.5028.2533.1748.1727.5822.5824.0841.3324.8320.7536.3335.4271.5828.6735.1739.5039.3324.3360.0823.0826.6748.1741.1755.9253.9218.9250.0865.4217.5818.8337.7523.2518.0822.5019.6722.0825.1747.4233.5027.6758.4220.6726.1721.3342.8338.1720.5048.2528.3318.7518.5033.1745.0019.6724.5021.8340.2541.4217.8323.17?18.1720.0020.0020.7524.5032.7552.1748.1720.4250.7517.0818.3332.0059.6718.0037.5832.3318.0838.2530.6718.5819.1718.1724.5816.2521.1723.9217.6716.5023.2517.58?29.5018.8321.7523.0018.2525.4235.7516.0831.9269.1732.9216.3322.1757.5818.2523.4215.9224.7548.7523.5018.5827.7531.7524.8319.0016.3318.5816.2523.0021.1717.5019.1736.7521.2518.0833.6748.5833.6729.5030.1740.8334.83?20.4233.2534.0825.2534.7527.6747.3334.8333.2528.0039.0842.7526.9233.7538.9262.7532.2526.7563.3327.8326.1722.1722.5030.7536.6716.0041.1719.5032.4236.7530.2523.0826.8316.9224.4242.8322.7539.4223.5821.4233.0026.3345.0026.2528.1720.8328.6720.6734.4233.5843.1722.6724.3356.8322.0834.0022.5821.1726.6722.9215.1739.9227.4224.7541.1733.0829.8323.5826.1731.0020.7528.9251.9222.6734.0069.5040.3319.5816.0017.0831.2525.1722.6740.5822.2522.2522.5023.5838.4226.5835.0020.4229.4226.1733.6724.5827.6737.5049.1733.5851.8322.9221.8325.2558.5819.0019.5853.3327.1725.9223.0839.5830.5817.2517.67?16.5027.3331.2520.00?39.5036.5029.7552.4236.1734.5829.6736.1725.6724.5024.0821.9236.5823.0027.5831.0830.4222.0816.3321.9221.0817.4219.1720.6726.7523.5839.1722.7526.5016.9223.5017.3323.7534.6774.8328.1724.5018.8345.3347.2524.1739.2520.5018.8319.1725.0020.1725.7520.42?39.0064.0828.2528.7531.3318.9224.7530.6721.0013.7546.0044.3320.2522.67?60.9216.0828.1739.1720.4230.0022.8322.5028.5845.1741.5857.0855.7543.2525.3324.5843.1740.9231.8333.9224.9235.2534.2580.2519.4242.7519.6736.3330.0844.2523.5823.9233.1748.3376.7551.3334.7538.5822.4241.9229.5832.1751.4222.8325.0026.7523.3324.4242.1720.8323.0825.1743.0835.7559.5021.0021.9265.1720.3332.2530.1725.1739.1739.0831.6741.0048.5032.6728.0873.4264.0851.5826.6725.3330.1727.0023.1734.1738.6725.7546.0821.5020.0820.5029.5042.2529.8320.0823.4229.5816.1732.33?47.8320.0027.5822.0019.3338.3329.4222.6732.2529.5818.4222.1722.6725.5818.8321.5823.7522.0036.0829.2519.5822.9227.2538.7532.4223.7518.1740.9219.5028.5835.5834.1733.1731.5852.5036.1737.3320.8324.0825.5835.1748.0815.8322.5021.5023.5821.0825.6738.9215.7528.5822.2529.8323.5032.0831.0831.8321.7517.9230.3351.8347.1725.8350.2529.5037.3341.5830.5819.4217.9220.0819.5027.8317.0836.4240.5821.0822.6725.2517.9235.00'\n 'uuuuuuuuyyuuuuuyuuuuuuuuuuuuuuuuuuuuuuyuuuuuyuyuuuuuuuuyuuuuuuyuuuuuuuuuuuyuuyyuuuuuuuuyuuyuyyyuyuyuyyuuyuuyyuuyuuyuuuuuuuuuuuuuuuuuuuuuyuuuuuyuuuuyuuuuuuuyyuuyuuuyuuuuuyyuuuuyuuuuuuuuuuuuuuuuuyyyyuyuuuuuyu?uuuuyuuyuuuuyuuuuuuuyuuuuuuuuuuuuyuuuuyuuuuuuuuuuuuuyuyuyuyyuuu?uyyuuuyyuyyuuuuuuyyuuuuuuuuuuuuuuuyuuuyuyuuyuylyyuluyuyyuyy?yuuuuuyyuuuuuuuuyuuuyyuuuuuuuuuuyuuuyyyyuuuuyuyuuuuyyuyyuuuuuuuyuyyyuyuuuyuyyuuuuuuuyyuuyuuuuuuuuuyyyuuuyuuuuuuyuyuuuuuyuuuuu?yuyyuuuuuuuuuuyuyuuuyuyuyuyuyyyyuuuuuyuuuuuuuuuuuuuuyyuuuyuuuuuuuuuuuuuuuuuuuuyuuuuyuyuyyyuuuuuuuyuuuuuuuuuuuuuyuuyyuuyuuuuuuuyyuuuyuuu?uuuuuuuuyyuuyuuyuyyuuuuuyuyuu?uyuyuuuuuuyuuyuuuuyyuyuuuuuuuuuuyuuuuuuuyyyuuuyuuuyuuuuuuuyuyuyuyuu'\n 'ggggggggppgggggpggggggggggggggggggggggpgggggpgpggggggggpggggggpgggggggggggpggppggggggggpggpgpppgpgpgppggpggppggpggpgggggggggggggggggggggpgggggpggggpgggggggppggpgggpgggggppggggpgggggggggggggggggppppgpgggggpg?ggggpggpggggpgggggggpggggggggggggpggggpgggggggggggggpgpgpgppggg?gppgggppgppggggggppgggggggggggggggpgggpgpggpgpggppggggpgppgpp?pgggggppggggggggpgggppggggggggggpgggppppggggpgpggggppgppgggggggpgpppgpgggpgppgggggggppggpgggggggggpppgggpggggggpgpgggggpggggg?pgppggggggggggpgpgggpgpgpgpgppppgggggpggggggggggggggppgggpggggggggggggggggggggpggggpgpgpppgggggggpgggggggggggggpggppggpgggggggppgggpggg?ggggggggppggpggpgppgggggpgpgg?gpgpggggggpggpggggppgpggggggggggpgggggggpppgggpgggpgggggggpgpgpgpgg'\n 'wqqwwmrcckwcckkqkmqdcccccxqcidewaaxieqwccxccffccwwccqcciccqwwccwccixqmdqqcccccmwxedccmcqaaaakcffmmdaacdaaaajccaacciaacqqccqkiekaaxcwffwkcqqkmccqccaaqqxmqiwececqqaamwqccjccwccccqqccccqmcccjxekmxmxeqqqccqdaackkqwaaaaqaaciqcqcaaccqcixwicxwaaxqicqwq?qkcccdfficcaaccffecaaeaaaaqckxqccccxxwiqiaaqxcwwqicccqcxeqxxkccdicdffixffcedqq?cmkccdiqffmccccqcwffwcjmwwwffffffaaaacffdcqqffffffkjwcaadaamcffmcwcccckwxciwi?ccdccqciaawcaaiikecccwjffmdiaadqdffkffkkemaamkrwekwaaedciiiciffkcaacimeiaamwdxffkcjciqiffkcwqffciikffkccffiqwccccweffccffckaacffffffffkkffmkjffcffffcicqwdw?ciccmcffjmcwkikiiicdiii?ikaacmffkaaffqqqmccwxcccxccffxccaaqcwwjcecxaacqxkemqqckikqcaaiffaaffffxw?ccikwidwdxmeirwxcwwxqccxcqqaawxcaawdxffcccccmxemweffxcccccc?wkccaaqck?kqckckdxkqwccciffmaaic?qccciffdwqmffkwcmaaaakiccaaaawcccaakffiqiiqffcaaccaacwccwmccdffwccaaeiaaqmffckdidmecffaac'\n 'vhhvvvhvhvhhvvvvvvhhvvvhvhbbbbhvvhbbvvvhhvffvhhvvhhhbbvhvvvhvvhhhvvvvvvvvhhbbbbvvvvvvvvffvvvvbbvvvjhvvhvbbvbbvvbbvvvhzvvhvvffvbbhvhvvhvvvvvhbbvbbvzvbbbbhhvvvhhffhvhhvhbbvhvhvhjhzhbbhvvhvhvvhvvbbhhhvvvvvbbbbvvvhbbvvhvhvvbbbbvhvvhbbvvvh?hvbbhvffvvvhffvvvzvvvbbvvvvvvhvbbvbbvvvvvvvvhhhbbvzhhhvhvvvvhffohffvddvvn?vvvhvhhffvhhvvvhffvvjvvvvffffffvvvffvvvhffffffhjvvvvvvhobbvvffvvvvvbbvv?vvvbbhvhvvvvbbbbvzvbbvvjffvvvvvvvffvffffvddvvvhnvddhvvddvvbbbbbbvbbffvvvvbbvvbbbbvvvhffhvvvbbvbbffvvvvffvvbbvffvvvffvvvvvvvvffvffvvvvffffffffvvffvvffffvffffvbbvvvvv?vbbvvvvffjvvhvhhhvvvvhhv?vvvvvffvvffvhvvhhvhvvvvvffvvvvhvvvjvddhvvvvvvddvvvvvbbhhhhbbffvffffhbb?vbbhvbbvvhvvzbbnvhhvvhhhhhhhvhhvvvvvffhhvvvvvvvhzffhvvvvh?vvbbvvvvv?vvhvvvvbbvhvbbvhvffvvvj?vvvbbffhvvhffffvnvvvvbbvvhvvvvhffbbvvvvffhvvvvvvvvvvvhffvvvhhvhvffvvhvvvhvffvh'\n 'ttttttttttfttfttttttttttttttttttttttttttttttttttffttttttttftttttttttttttttfttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttfttttttttttttttttttttttttttttttttttttfttttttttttttttttttttfttttttttttttttttttttttttttfffffffffffffftfffffffffftffffffffffffffffffffffffftffffffffftffffffftfffffffffffffffffffffffftffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffftttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttfttttttttttffttttfttffftfffffffffffffftffffffffffffffffffffffffffffffffftffffffffffffffffffffffffffffffffffff'\n 'ttftffffffffffttttfttftttttttttttfttttttttttttttffffffffffftttttttttttffffftfftftfffffffffffffffffftffttttffftttfttttttttttttttttftttttftttttttttttttttttttttttttttfffffffffffffffttttttttttttfffttttttttfttttfttttftttfttttttfffffftftttfttftftftftttttttttttfffffffffffffffffffffffffffffttttttffttttttttttfffffffffffffffffffffftffffffffffffffffffffffffttffffftffffffffttffffffffffffffffffffffffffffffffffffffffttttttfffffftffffffffffffffffttfttttfffffftfffffffffffftftttttffffffffffffttttftfffftttffffttttttttttttttfffffttttttttffffttfffffffffffffftftttfttttttttfttffffftfttttttttttttttffffttttttfffftttttfffffffffftttfttttfffffffffffftffttffffffffffffftftfftftfftffffffftffffffffttffffffffttff'\n 'ggggsggggggggggggggggsggggggggggggggggggggggggggggggggggggsgggggggggggsggsgggggggssggssggggggggggsggggggggsggggggggggggggggggggggsggggggggggggggggggggggggggggggggggggggggggggggsggggsggggggggggggggggggggggggpggggsgggsggggggggggggggggggggggsgsgggggggggggggggggggggggggggggpgggsggggsggsgggggggsggggggggggssgggggsggggggsgpsggsgggggssgpggggggggggggggggggggggsggggggsggsgggsggggsggggsgsgggggggsgsgggggggggggggsgsgggggggsggggggggggpggggggggggggsggsgsgggggggggggggpggggggggggggggggggggsgsggggsggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggsgggsgggggggggggggggggggggggggggggggsggggggggggpggggggggggggggggggggggggggggspggsggggggggggggggggggggggggggsgggggggggggsgggsgggggggggggggggsggggg'\n '++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++-----------------------------------------------+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++--------------+++----------------------------------------------+++++++----------------------------------------------------------------------------------------------------------------------------------------------------------------------+++++++++++++++++++++++++++++++++------------------------++++++++++++++++++++++++++++++++++++++++++++++++++++++-----+--------------++-------------------------------------------------------------------'] to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cc_apps_train\u001b[38;5;241m.\u001b[39mfillna(\u001b[43mcc_apps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m cc_apps_test\u001b[38;5;241m.\u001b[39mfillna(cc_apps\u001b[38;5;241m.\u001b[39mmean(), inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:11335\u001b[0m, in \u001b[0;36mDataFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11327\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m  11328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  11329\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11333\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11334\u001b[0m ):\n\u001b[1;32m> 11335\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  11336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Series):\n\u001b[0;32m  11337\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:11992\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11985\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  11986\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  11987\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11990\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11991\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 11992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  11993\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m  11994\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:11949\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11945\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[0;32m  11947\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 11949\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  11950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[0;32m  11951\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:11204\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m  11200\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m  11202\u001b[0m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[0;32m  11203\u001b[0m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[1;32m> 11204\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblk_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  11205\u001b[0m out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(res, axes\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m  11206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboolean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1459\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1457\u001b[0m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1458\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m-> 1459\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1460\u001b[0m     res_blocks\u001b[38;5;241m.\u001b[39mextend(nbs)\n\u001b[0;32m   1462\u001b[0m index \u001b[38;5;241m=\u001b[39m Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:377\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m--> 377\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    380\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:11136\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[1;34m(values, axis)\u001b[0m\n\u001b[0;32m  11134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([result])\n\u001b[0;32m  11135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m> 11136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:720\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    718\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[0;32m    719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[1;32m--> 720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthe_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    723\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:1678\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1675\u001b[0m inferred \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(x)\n\u001b[0;32m   1676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m   1677\u001b[0m     \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[1;32m-> 1678\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1679\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1680\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mcomplex128)\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert ['baabbbbabbbbababbababbaaaaabbbbbbaabbabbbbbbbbabbbabbbbbbbbbbbaabbabbbbbabbbbabbbababbbbbabbbbbabbaabbbbbbbabababababbbabbaaabbbbabbabbbbbaaaabbbbbaaaaabbbaaabbbbbbaababbabbabbbaabbaaaabbbaabbbbbbbbbbaababaabbbbbbbbbbbbaabaaabbabbbabbaabbbbbbbabbba?bbbabbbbbaabaaabbbabbbbbbbbaabbbbbabbabbababbaabbbbabbaabbbbaabaabbbbbbbaabbab?bbbababbbaababbbbb?bbbabbbbababaabbbbbababbbab?abbbbbaaabbbbbbbbbbbababbbbaabaaabbbbabbabbbabbbbbbabbbbbbbbbbaabbbbbaababbbbb?bbbbbbabbaaababbabbbbbbbb?ababbbbbb?abbaababbbbbababaaabbaabbbabab?abaabbaabaabbbaabbbbbbbbbbbbbbbbbabbabaabbbbabababbbaabbbbbbbbbabbbbbbbbbbbaa?ba?bbbabbbbbbbbabbbbbbbabbbbbbaaaababbbbbb?babbabbabaabaabaaabbabbbaabbbba?aaabaabbbbbbaabb'\n '30.8358.6724.5027.8320.1732.0833.1722.9254.4242.5022.0829.9238.2548.0845.8336.6728.2523.2521.8319.1725.0023.2547.7527.4241.1715.8347.0056.5857.4242.0829.2542.0049.5036.7522.5827.8327.2523.0027.7554.5834.1728.9229.6739.5856.4254.3341.0031.9241.5023.9225.7526.0037.4234.9234.2523.3323.1744.3335.1743.2556.7531.6723.4220.4226.6734.1736.0025.5019.4235.1732.3334.8338.5844.2544.8320.6734.0819.1721.6721.5049.5827.6739.83?27.2537.17?25.6734.0049.0062.5031.42?52.3328.7528.5823.00?22.5028.5037.5035.2518.6725.0027.8354.8328.7525.0040.9219.7529.1724.5024.5833.7520.6725.4237.7552.5057.8320.7539.9225.6724.7544.1723.5034.9247.6722.7534.4228.4267.7520.4247.4236.2532.6748.5839.9233.5818.8326.9231.2556.5043.0022.3327.2532.8323.2540.3330.5052.8346.6758.3337.3323.0832.7521.6728.5068.6728.0034.0827.6744.0025.0832.0060.5840.8319.3332.3336.6737.5025.0841.3356.0049.8322.6727.0025.0026.0818.4220.1747.6721.2520.6757.0822.4248.7540.0040.5828.6733.0821.3342.0041.7522.6734.5028.2533.1748.1727.5822.5824.0841.3324.8320.7536.3335.4271.5828.6735.1739.5039.3324.3360.0823.0826.6748.1741.1755.9253.9218.9250.0865.4217.5818.8337.7523.2518.0822.5019.6722.0825.1747.4233.5027.6758.4220.6726.1721.3342.8338.1720.5048.2528.3318.7518.5033.1745.0019.6724.5021.8340.2541.4217.8323.17?18.1720.0020.0020.7524.5032.7552.1748.1720.4250.7517.0818.3332.0059.6718.0037.5832.3318.0838.2530.6718.5819.1718.1724.5816.2521.1723.9217.6716.5023.2517.58?29.5018.8321.7523.0018.2525.4235.7516.0831.9269.1732.9216.3322.1757.5818.2523.4215.9224.7548.7523.5018.5827.7531.7524.8319.0016.3318.5816.2523.0021.1717.5019.1736.7521.2518.0833.6748.5833.6729.5030.1740.8334.83?20.4233.2534.0825.2534.7527.6747.3334.8333.2528.0039.0842.7526.9233.7538.9262.7532.2526.7563.3327.8326.1722.1722.5030.7536.6716.0041.1719.5032.4236.7530.2523.0826.8316.9224.4242.8322.7539.4223.5821.4233.0026.3345.0026.2528.1720.8328.6720.6734.4233.5843.1722.6724.3356.8322.0834.0022.5821.1726.6722.9215.1739.9227.4224.7541.1733.0829.8323.5826.1731.0020.7528.9251.9222.6734.0069.5040.3319.5816.0017.0831.2525.1722.6740.5822.2522.2522.5023.5838.4226.5835.0020.4229.4226.1733.6724.5827.6737.5049.1733.5851.8322.9221.8325.2558.5819.0019.5853.3327.1725.9223.0839.5830.5817.2517.67?16.5027.3331.2520.00?39.5036.5029.7552.4236.1734.5829.6736.1725.6724.5024.0821.9236.5823.0027.5831.0830.4222.0816.3321.9221.0817.4219.1720.6726.7523.5839.1722.7526.5016.9223.5017.3323.7534.6774.8328.1724.5018.8345.3347.2524.1739.2520.5018.8319.1725.0020.1725.7520.42?39.0064.0828.2528.7531.3318.9224.7530.6721.0013.7546.0044.3320.2522.67?60.9216.0828.1739.1720.4230.0022.8322.5028.5845.1741.5857.0855.7543.2525.3324.5843.1740.9231.8333.9224.9235.2534.2580.2519.4242.7519.6736.3330.0844.2523.5823.9233.1748.3376.7551.3334.7538.5822.4241.9229.5832.1751.4222.8325.0026.7523.3324.4242.1720.8323.0825.1743.0835.7559.5021.0021.9265.1720.3332.2530.1725.1739.1739.0831.6741.0048.5032.6728.0873.4264.0851.5826.6725.3330.1727.0023.1734.1738.6725.7546.0821.5020.0820.5029.5042.2529.8320.0823.4229.5816.1732.33?47.8320.0027.5822.0019.3338.3329.4222.6732.2529.5818.4222.1722.6725.5818.8321.5823.7522.0036.0829.2519.5822.9227.2538.7532.4223.7518.1740.9219.5028.5835.5834.1733.1731.5852.5036.1737.3320.8324.0825.5835.1748.0815.8322.5021.5023.5821.0825.6738.9215.7528.5822.2529.8323.5032.0831.0831.8321.7517.9230.3351.8347.1725.8350.2529.5037.3341.5830.5819.4217.9220.0819.5027.8317.0836.4240.5821.0822.6725.2517.9235.00'\n 'uuuuuuuuyyuuuuuyuuuuuuuuuuuuuuuuuuuuuuyuuuuuyuyuuuuuuuuyuuuuuuyuuuuuuuuuuuyuuyyuuuuuuuuyuuyuyyyuyuyuyyuuyuuyyuuyuuyuuuuuuuuuuuuuuuuuuuuuyuuuuuyuuuuyuuuuuuuyyuuyuuuyuuuuuyyuuuuyuuuuuuuuuuuuuuuuuyyyyuyuuuuuyu?uuuuyuuyuuuuyuuuuuuuyuuuuuuuuuuuuyuuuuyuuuuuuuuuuuuuyuyuyuyyuuu?uyyuuuyyuyyuuuuuuyyuuuuuuuuuuuuuuuyuuuyuyuuyuylyyuluyuyyuyy?yuuuuuyyuuuuuuuuyuuuyyuuuuuuuuuuyuuuyyyyuuuuyuyuuuuyyuyyuuuuuuuyuyyyuyuuuyuyyuuuuuuuyyuuyuuuuuuuuuyyyuuuyuuuuuuyuyuuuuuyuuuuu?yuyyuuuuuuuuuuyuyuuuyuyuyuyuyyyyuuuuuyuuuuuuuuuuuuuuyyuuuyuuuuuuuuuuuuuuuuuuuuyuuuuyuyuyyyuuuuuuuyuuuuuuuuuuuuuyuuyyuuyuuuuuuuyyuuuyuuu?uuuuuuuuyyuuyuuyuyyuuuuuyuyuu?uyuyuuuuuuyuuyuuuuyyuyuuuuuuuuuuyuuuuuuuyyyuuuyuuuyuuuuuuuyuyuyuyuu'\n 'ggggggggppgggggpggggggggggggggggggggggpgggggpgpggggggggpggggggpgggggggggggpggppggggggggpggpgpppgpgpgppggpggppggpggpgggggggggggggggggggggpgggggpggggpgggggggppggpgggpgggggppggggpgggggggggggggggggppppgpgggggpg?ggggpggpggggpgggggggpggggggggggggpggggpgggggggggggggpgpgpgppggg?gppgggppgppggggggppgggggggggggggggpgggpgpggpgpggppggggpgppgpp?pgggggppggggggggpgggppggggggggggpgggppppggggpgpggggppgppgggggggpgpppgpgggpgppgggggggppggpgggggggggpppgggpggggggpgpgggggpggggg?pgppggggggggggpgpgggpgpgpgpgppppgggggpggggggggggggggppgggpggggggggggggggggggggpggggpgpgpppgggggggpgggggggggggggpggppggpgggggggppgggpggg?ggggggggppggpggpgppgggggpgpgg?gpgpggggggpggpggggppgpggggggggggpgggggggpppgggpgggpgggggggpgpgpgpgg'\n 'wqqwwmrcckwcckkqkmqdcccccxqcidewaaxieqwccxccffccwwccqcciccqwwccwccixqmdqqcccccmwxedccmcqaaaakcffmmdaacdaaaajccaacciaacqqccqkiekaaxcwffwkcqqkmccqccaaqqxmqiwececqqaamwqccjccwccccqqccccqmcccjxekmxmxeqqqccqdaackkqwaaaaqaaciqcqcaaccqcixwicxwaaxqicqwq?qkcccdfficcaaccffecaaeaaaaqckxqccccxxwiqiaaqxcwwqicccqcxeqxxkccdicdffixffcedqq?cmkccdiqffmccccqcwffwcjmwwwffffffaaaacffdcqqffffffkjwcaadaamcffmcwcccckwxciwi?ccdccqciaawcaaiikecccwjffmdiaadqdffkffkkemaamkrwekwaaedciiiciffkcaacimeiaamwdxffkcjciqiffkcwqffciikffkccffiqwccccweffccffckaacffffffffkkffmkjffcffffcicqwdw?ciccmcffjmcwkikiiicdiii?ikaacmffkaaffqqqmccwxcccxccffxccaaqcwwjcecxaacqxkemqqckikqcaaiffaaffffxw?ccikwidwdxmeirwxcwwxqccxcqqaawxcaawdxffcccccmxemweffxcccccc?wkccaaqck?kqckckdxkqwccciffmaaic?qccciffdwqmffkwcmaaaakiccaaaawcccaakffiqiiqffcaaccaacwccwmccdffwccaaeiaaqmffckdidmecffaac'\n 'vhhvvvhvhvhhvvvvvvhhvvvhvhbbbbhvvhbbvvvhhvffvhhvvhhhbbvhvvvhvvhhhvvvvvvvvhhbbbbvvvvvvvvffvvvvbbvvvjhvvhvbbvbbvvbbvvvhzvvhvvffvbbhvhvvhvvvvvhbbvbbvzvbbbbhhvvvhhffhvhhvhbbvhvhvhjhzhbbhvvhvhvvhvvbbhhhvvvvvbbbbvvvhbbvvhvhvvbbbbvhvvhbbvvvh?hvbbhvffvvvhffvvvzvvvbbvvvvvvhvbbvbbvvvvvvvvhhhbbvzhhhvhvvvvhffohffvddvvn?vvvhvhhffvhhvvvhffvvjvvvvffffffvvvffvvvhffffffhjvvvvvvhobbvvffvvvvvbbvv?vvvbbhvhvvvvbbbbvzvbbvvjffvvvvvvvffvffffvddvvvhnvddhvvddvvbbbbbbvbbffvvvvbbvvbbbbvvvhffhvvvbbvbbffvvvvffvvbbvffvvvffvvvvvvvvffvffvvvvffffffffvvffvvffffvffffvbbvvvvv?vbbvvvvffjvvhvhhhvvvvhhv?vvvvvffvvffvhvvhhvhvvvvvffvvvvhvvvjvddhvvvvvvddvvvvvbbhhhhbbffvffffhbb?vbbhvbbvvhvvzbbnvhhvvhhhhhhhvhhvvvvvffhhvvvvvvvhzffhvvvvh?vvbbvvvvv?vvhvvvvbbvhvbbvhvffvvvj?vvvbbffhvvhffffvnvvvvbbvvhvvvvhffbbvvvvffhvvvvvvvvvvvhffvvvhhvhvffvvhvvvhvffvh'\n 'ttttttttttfttfttttttttttttttttttttttttttttttttttffttttttttftttttttttttttttfttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttfttttttttttttttttttttttttttttttttttttfttttttttttttttttttttfttttttttttttttttttttttttttfffffffffffffftfffffffffftffffffffffffffffffffffffftffffffffftffffffftfffffffffffffffffffffffftffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffftttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttfttttttttttffttttfttffftfffffffffffffftffffffffffffffffffffffffffffffffftffffffffffffffffffffffffffffffffffff'\n 'ttftffffffffffttttfttftttttttttttfttttttttttttttffffffffffftttttttttttffffftfftftfffffffffffffffffftffttttffftttfttttttttttttttttftttttftttttttttttttttttttttttttttfffffffffffffffttttttttttttfffttttttttfttttfttttftttfttttttfffffftftttfttftftftftttttttttttfffffffffffffffffffffffffffffttttttffttttttttttfffffffffffffffffffffftffffffffffffffffffffffffttffffftffffffffttffffffffffffffffffffffffffffffffffffffffttttttfffffftffffffffffffffffttfttttfffffftfffffffffffftftttttffffffffffffttttftfffftttffffttttttttttttttfffffttttttttffffttfffffffffffffftftttfttttttttfttffffftfttttttttttttttffffttttttfffftttttfffffffffftttfttttfffffffffffftffttffffffffffffftftfftftfftffffffftffffffffttffffffffttff'\n 'ggggsggggggggggggggggsggggggggggggggggggggggggggggggggggggsgggggggggggsggsgggggggssggssggggggggggsggggggggsggggggggggggggggggggggsggggggggggggggggggggggggggggggggggggggggggggggsggggsggggggggggggggggggggggggpggggsgggsggggggggggggggggggggggsgsgggggggggggggggggggggggggggggpgggsggggsggsgggggggsggggggggggssgggggsggggggsgpsggsgggggssgpggggggggggggggggggggggsggggggsggsgggsggggsggggsgsgggggggsgsgggggggggggggsgsgggggggsggggggggggpggggggggggggsggsgsgggggggggggggpggggggggggggggggggggsgsggggsggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggsgggsgggggggggggggggggggggggggggggggsggggggggggpggggggggggggggggggggggggggggspggsggggggggggggggggggggggggggsgggggggggggsgggsgggggggggggggggsggggg'\n '++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++-----------------------------------------------+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++--------------+++----------------------------------------------+++++++----------------------------------------------------------------------------------------------------------------------------------------------------------------------+++++++++++++++++++++++++++++++++------------------------++++++++++++++++++++++++++++++++++++++++++++++++++++++-----+--------------++-------------------------------------------------------------------'] to numeric"
     ]
    }
   ],
   "source": [
    "cc_apps_train.fillna(cc_apps.mean(), inplace=True)\n",
    "cc_apps_test.fillna(cc_apps.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c33eef5-01bc-49f3-a1a3-be76a50b9d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "12    0\n",
      "14    0\n",
      "15    0\n",
      "dtype: int64\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "12    0\n",
      "14    0\n",
      "15    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in cc_apps_train.columns:\n",
    "    # Check if the column is of object type\n",
    "    if cc_apps_train[col].dtypes == 'object':\n",
    "        # Impute with the most frequent value\n",
    "        cc_apps_train = cc_apps_train.fillna(cc_apps_train[col].value_counts().index[0])\n",
    "        cc_apps_test = cc_apps_test.fillna(cc_apps_train[col].value_counts().index[0])\n",
    "\n",
    "# Count the number of NaNs in the dataset and print the counts to verify\n",
    "print(cc_apps_train.isnull().sum())\n",
    "print(cc_apps_test.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83933471-4d21-4b21-83a6-84d457d10bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the categorical features in the train and test sets independently\n",
    "cc_apps_train = pd.get_dummies(cc_apps_train)\n",
    "cc_apps_test = pd.get_dummies(cc_apps_test)\n",
    "\n",
    "# Reindex the columns of the test set aligning with the train set\n",
    "cc_apps_test = cc_apps_test.reindex(columns=cc_apps_train.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b8cd6d8-799f-4635-954a-ac79171de4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Segregate features and labels into separate variables\n",
    "X_train, y_train = cc_apps_train.iloc[:, :-1].values, cc_apps_train.iloc[:, [-1]].values\n",
    "X_test, y_test = cc_apps_test.iloc[:, :-1].values, cc_apps_test.iloc[:, [-1]].values\n",
    "\n",
    "# Instantiate MinMaxScaler and use it to rescale X_train and X_test\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX_train = scaler.fit_transform(X_train)\n",
    "rescaledX_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bedc173-3234-46d3-acd2-6e125575e18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate a LogisticRegression classifier with default parameter values\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit logreg to the train set\n",
    "logreg.fit(rescaledX_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ca12cdf-4a03-4463-b117-02ebd6b29b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier:  1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[103,   0],\n",
       "       [  0, 125]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Use logreg to predict instances from the test set and store it\n",
    "y_pred = logreg.predict(rescaledX_test)\n",
    "\n",
    "# Get the accuracy score of logreg model and print it\n",
    "print(\"Accuracy of logistic regression classifier: \", logreg.score(rescaledX_test,y_test))\n",
    "\n",
    "# Print the confusion matrix of the logreg model\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66c80d9e-f04a-431f-b053-a377f2a423bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the grid of values for tol and max_iter\n",
    "tol = [0.01, 0.001 ,0.0001]\n",
    "max_iter = [100, 150, 200]\n",
    "\n",
    "# Create a dictionary where tol and max_iter are keys and the lists of their values are the corresponding values\n",
    "param_grid = dict(tol=tol, max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8218240-cee1-4281-b318-828905bc5d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 1.000000 using {'max_iter': 100, 'tol': 0.01}\n",
      "Accuracy of logistic regression classifier:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\shivr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate GridSearchCV with the required parameters\n",
    "grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit grid_model to the data\n",
    "grid_model_result = grid_model.fit(rescaledX_train, y_train)\n",
    "\n",
    "# Summarize results\n",
    "best_score, best_params = grid_model_result.best_score_, grid_model_result.best_params_\n",
    "print(\"Best: %f using %s\" % (best_score, best_params))\n",
    "\n",
    "# Extract the best model and evaluate it on the test set\n",
    "best_model = grid_model_result.best_estimator_\n",
    "print(\"Accuracy of logistic regression classifier: \", best_model.score(rescaledX_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
